{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a283c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from btgp.data_utils import load_dataset\n",
    "from btgp.gp import ONGP, bit_order_to_inv_permutation\n",
    "from btgp.gp_mixture import GPInfo, GPMixture\n",
    "import torch\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa17e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "#     \"pol\",\n",
    "#     \"elevators\",\n",
    "#     \"bike\",\n",
    "#     \"kin40k\",\n",
    "#     \"protein\",\n",
    "#     \"keggdirected\",\n",
    "#     \"slice\",\n",
    "#     \"keggundirected\",\n",
    "#     \"3droad\",\n",
    "#     \"song\",\n",
    "#     \"buzz\",\n",
    "    \"houseelectric\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5e12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from math import ceil\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.distributions import Normal\n",
    "from torch.quasirandom import SobolEngine\n",
    "def initialize_q_batch(X: Tensor, Y: Tensor, n: int, eta: float = 1.0) -> Tensor:\n",
    "    r\"\"\"Heuristic for selecting initial conditions for candidate generation.\n",
    "    This heuristic selects points from `X` (without replacement) with probability\n",
    "    proportional to `exp(eta * Z)`, where `Z = (Y - mean(Y)) / std(Y)` and `eta`\n",
    "    is a temperature parameter.\n",
    "    When using an acquisiton function that is non-negative and possibly zero\n",
    "    over large areas of the feature space (e.g. qEI), you should use\n",
    "    `initialize_q_batch_nonneg` instead.\n",
    "    Args:\n",
    "        X: A `b x batch_shape x q x d` tensor of `b` - `batch_shape` samples of\n",
    "            `q`-batches from a d`-dim feature space. Typically, these are generated\n",
    "            using qMC sampling.\n",
    "        Y: A tensor of `b x batch_shape` outcomes associated with the samples.\n",
    "            Typically, this is the value of the batch acquisition function to be\n",
    "            maximized.\n",
    "        n: The number of initial condition to be generated. Must be less than `b`.\n",
    "        eta: Temperature parameter for weighting samples.\n",
    "    Returns:\n",
    "        A `n x batch_shape x q x d` tensor of `n` - `batch_shape` `q`-batch initial\n",
    "        conditions, where each batch of `n x q x d` samples is selected independently.\n",
    "    Example:\n",
    "        >>> # To get `n=10` starting points of q-batch size `q=3`\n",
    "        >>> # for model with `d=6`:\n",
    "        >>> qUCB = qUpperConfidenceBound(model, beta=0.1)\n",
    "        >>> Xrnd = torch.rand(500, 3, 6)\n",
    "        >>> Xinit = initialize_q_batch(Xrnd, qUCB(Xrnd), 10)\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    batch_shape = X.shape[1:-2] or torch.Size()\n",
    "    if n > n_samples:\n",
    "        raise RuntimeError(\n",
    "            f\"n ({n}) cannot be larger than the number of \"\n",
    "            f\"provided samples ({n_samples})\"\n",
    "        )\n",
    "    elif n == n_samples:\n",
    "        return X\n",
    "\n",
    "    Ystd = Y.std(dim=0)\n",
    "    if torch.any(Ystd == 0):\n",
    "        warnings.warn(\n",
    "            \"All acquisition values for raw samples points are the same for \"\n",
    "            \"at least one batch. Choosing initial conditions at random.\",\n",
    "            RuntimeWarning,\n",
    "        )\n",
    "        return X[torch.randperm(n=n_samples, device=X.device)][:n]\n",
    "\n",
    "    max_val, max_idx = torch.max(Y, dim=0)\n",
    "    Z = (Y - Y.mean(dim=0)) / Ystd\n",
    "    etaZ = eta * Z\n",
    "    weights = torch.exp(etaZ)\n",
    "    while torch.isinf(weights).any():\n",
    "        etaZ *= 0.5\n",
    "        weights = torch.exp(etaZ)\n",
    "    if batch_shape == torch.Size():\n",
    "        idcs = torch.multinomial(weights, n)\n",
    "    else:\n",
    "        idcs = batched_multinomial(\n",
    "            weights=weights.permute(*range(1, len(batch_shape) + 1), 0), num_samples=n\n",
    "        ).permute(-1, *range(len(batch_shape)))\n",
    "    # make sure we get the maximum\n",
    "    if max_idx not in idcs:\n",
    "        idcs[-1] = max_idx\n",
    "    if batch_shape == torch.Size():\n",
    "        return X[idcs]\n",
    "    else:\n",
    "        return X.gather(\n",
    "            dim=0, index=idcs.view(*idcs.shape, 1, 1).expand(n, *X.shape[1:])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e9180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bit_order(gp, n=20, raw_samples=1000):\n",
    "    bit_orders_weights = []\n",
    "    train_nlls = []\n",
    "    # initialize bit order\n",
    "    orig_weight = gp.weights[-1].item()\n",
    "    for _ in range(raw_samples):\n",
    "        for weight in (orig_weight, 0.5, 0.9):\n",
    "            gp.weights[-1] = weight\n",
    "            gp.weights[:-1] = (1-weight)/(gp.weights.shape[0]-1)\n",
    "            gp.random_bit_order()\n",
    "    #         gp.random_weights()\n",
    "            bit_orders_weights.append(torch.cat([gp.bit_order.clone(), gp.weights[-1:].clone().view(1,1).expand(gp.bit_order.shape[0], 1)], dim=-1))\n",
    "            gp.process()\n",
    "            train_nlls.append(gp.nll)\n",
    "    return initialize_q_batch(X=torch.stack(bit_orders_weights, dim=0), Y=-torch.stack(train_nlls), n=n)\n",
    "#     return bit_orders, train_nlls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7219a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_path: ../data/uci/houseelectric/houseelectric.mat\n",
      "data.shape: torch.Size([2049280, 12])\n",
      "train_x.shape: torch.Size([1311539, 11])\n",
      "full kernel size: 6408.0 GB\n",
      "train_x: min 0.000, max 1.000, mean 0.325, std 0.319\n",
      "val_x: min 0.000, max 1.000, mean 0.325, std 0.319\n",
      "test_x: min -0.009, max 1.000, mean 0.325, std 0.319\n",
      "train_y: min -2.300, max 2.867, mean -0.000, std 1.000\n",
      "val_y: min -2.300, max 2.772, mean -0.000, std 0.999\n",
      "test_y: min -2.300, max 2.824, mean -0.001, std 0.999\n",
      "\n",
      "finished loading data 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdaulton/anaconda3/envs/effgp/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing 0\n",
      "finished initializing 0\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 0\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 1\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 2\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 3\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 4\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 5\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 6\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 7\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 8\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 9\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 10\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 11\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 12\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 13\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 14\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 15\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 16\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 17\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 18\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 19\n",
      "dataset_path: ../data/uci/houseelectric/houseelectric.mat\n",
      "data.shape: torch.Size([2049280, 12])\n",
      "train_x.shape: torch.Size([1311539, 11])\n",
      "full kernel size: 6408.0 GB\n",
      "train_x: min 0.000, max 1.000, mean 0.326, std 0.320\n",
      "val_x: min -0.022, max 1.019, mean 0.326, std 0.320\n",
      "test_x: min 0.000, max 1.017, mean 0.326, std 0.319\n",
      "train_y: min -2.300, max 2.866, mean -0.000, std 1.000\n",
      "val_y: min -2.300, max 2.721, mean -0.002, std 0.999\n",
      "test_y: min -2.300, max 2.791, mean -0.000, std 0.999\n",
      "\n",
      "finished loading data 1\n",
      "initializing 1\n",
      "finished initializing 1\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 0\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 1\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 2\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 3\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 4\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 5\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 6\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 7\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 8\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 9\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 10\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 11\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 12\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 13\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 14\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 15\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 16\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 17\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 18\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 19\n",
      "dataset_path: ../data/uci/houseelectric/houseelectric.mat\n",
      "data.shape: torch.Size([2049280, 12])\n",
      "train_x.shape: torch.Size([1311539, 11])\n",
      "full kernel size: 6408.0 GB\n",
      "train_x: min 0.000, max 1.000, mean 0.326, std 0.320\n",
      "val_x: min 0.000, max 1.006, mean 0.326, std 0.320\n",
      "test_x: min 0.000, max 1.013, mean 0.326, std 0.320\n",
      "train_y: min -2.300, max 2.868, mean 0.000, std 1.000\n",
      "val_y: min -2.273, max 2.812, mean 0.001, std 0.999\n",
      "test_y: min -2.300, max 2.787, mean 0.002, std 1.001\n",
      "\n",
      "finished loading data 2\n",
      "initializing 2\n",
      "finished initializing 2\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 0\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 1\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 2\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 3\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 4\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 5\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 6\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 7\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 8\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 9\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 10\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 11\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 12\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 13\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 14\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 15\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 16\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 17\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 18\n",
      "Training the weight vector and the bit order:\n",
      "Finished restart 19\n"
     ]
    }
   ],
   "source": [
    "path_start = \"../data/uci/\"\n",
    "test_rmses_all = {}\n",
    "test_nlls_all = {}\n",
    "train_times_all = {}\n",
    "predict_times_all = {}\n",
    "init_times_all = {}\n",
    "mixture_rmse_all_perf_weighting = {}\n",
    "mixture_nll_all_perf_weighting = {}\n",
    "mixture_rmse_all_uniform_weighting = {}\n",
    "mixture_nll_all_uniform_weighting = {}\n",
    "all_init_bit_orders = {}\n",
    "all_final_bit_orders = {}\n",
    "all_last_bit_weights = {}\n",
    "SEEDS = [0,1,2]\n",
    "torch.manual_seed(0)\n",
    "NUM_RESTARTS = 20\n",
    "RAW_SAMPLES = 160\n",
    "n_gps = NUM_RESTARTS\n",
    "\n",
    "performance_weighting = 100 # maybe sqrt(n data points) is a good anchor?\n",
    "\n",
    "for name in datasets:\n",
    "    test_rmses = []\n",
    "    test_nlls = []\n",
    "    mixture_rmse_perf_weightings = []\n",
    "    mixture_nll_perf_weightings = []\n",
    "    mixture_rmse_uniform_weightings = []\n",
    "    mixture_nll_uniform_weightings = []\n",
    "    mixture_init_bit_orders = []\n",
    "    mixture_last_bit_weights = []\n",
    "    mixture_final_bit_orders = []\n",
    "    train_times = []\n",
    "    predict_times = []\n",
    "    init_times = []\n",
    "    torch.manual_seed(0)\n",
    "    for seed in SEEDS:\n",
    "        mixture_rmse_perf_weighting = {}\n",
    "        mixture_nll_perf_weighting = {}\n",
    "        mixture_rmse_uniform_weighting = {}\n",
    "        mixture_nll_uniform_weighting = {}\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y = load_dataset(\n",
    "            path_start + f\"{name}/{name}.mat\",\n",
    "            random_split=seed,\n",
    "        )\n",
    "        print(f\"finished loading data {seed}\")\n",
    "        train_x = train_x.to(dtype=torch.float64, device=device)\n",
    "        train_y = train_y.to(dtype=torch.float64, device=device)\n",
    "        test_x = test_x.to(dtype=torch.float64, device=device)\n",
    "        test_y = test_y.to(device=device, dtype=torch.float64)\n",
    "        del val_x, val_y\n",
    "        LAMBDA = 1/train_x.shape[0]\n",
    "        gp = ONGP(train_x, train_y, test_x, lambd=1e-5, precision=\"auto\")\n",
    "        # initialize bit order\n",
    "        init_time = time.time()\n",
    "        print(f\"initializing {seed}\")\n",
    "        bit_orders = initialize_bit_order(gp, n=NUM_RESTARTS, raw_samples=RAW_SAMPLES)\n",
    "        print(f\"finished initializing {seed}\")\n",
    "        mixture_init_bit_orders.append(bit_orders.clone())\n",
    "        last_bit_weights = bit_orders[:,0, -1]\n",
    "        bit_orders = bit_orders[:,:, :-1].long()\n",
    "        \n",
    "        init_times.append(time.time()-init_time)\n",
    "        _test_nlls = []\n",
    "        _test_rmses = []\n",
    "        _train_nlls = []\n",
    "        gp_info_list = []\n",
    "        for i in range(NUM_RESTARTS):\n",
    "            gp.weights[-1] = last_bit_weights[i]\n",
    "            gp.weights[:-1].fill_((1-last_bit_weights[i])/(gp.weights.shape[0]-1))\n",
    "            gp.bit_order = bit_orders[i]\n",
    "            gp.bit_order_inv_perm = bit_order_to_inv_permutation(gp.bit_order, gp.precision)\n",
    "            \n",
    "            mixture_init_bit_orders.append(bit_orders[i].clone())\n",
    "            mixture_last_bit_weights.append(last_bit_weights[i].clone())\n",
    "            gp.process()\n",
    "            print(\"Training the weight vector and the bit order:\")\n",
    "            train_time = time.time()\n",
    "            gp.opt_weights_and_bit_order_bfgs(max_iter=1000, verbose=False)\n",
    "            mixture_final_bit_orders.append(gp.bit_order.clone())\n",
    "            train_times.append(time.time() - train_time)\n",
    "            gp.save(path=f\"{name}_seed{seed}_gp{i}___\")\n",
    "            _train_nlls.append(gp.nll)\n",
    "            predict_time = time.time()\n",
    "            test_nll = gp.calculate_test_nll(test_y)\n",
    "            predict_times.append(time.time() - predict_time)\n",
    "            _test_nlls.append(test_nll)\n",
    "            test_rmse = gp.rmse(test_y.view(-1))\n",
    "            _test_rmses.append(test_rmse)\n",
    "            print(f\"Finished restart {i}\")\n",
    "            \n",
    "            gp_info_list.append(GPInfo(gp))\n",
    "            del gp\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            gp = ONGP(train_x, train_y, test_x, lambd=LAMBDA, precision=\"auto\")\n",
    "        del gp\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        best_idx = torch.argmin(torch.stack(_train_nlls)).item()\n",
    "        test_nlls.append(_test_nlls[best_idx])\n",
    "        test_rmses.append(_test_rmses[best_idx])\n",
    "        _gp_pop = GPMixture(train_x, train_y, test_x, lambd=LAMBDA)\n",
    "        for n_gps in (5, 10, 15, 20):\n",
    "            for j in range(5):\n",
    "                _gp_pop.add(gp_info_list[n_gps - 5 + j])\n",
    "                _gp_pop.process_index(-1)\n",
    "            _gp_pop.get_nlls()\n",
    "            # compute NLL, RMSE using performance weighting\n",
    "            test_nll_perf_weighting = _gp_pop.gp_mixture_nll(test_y, weight_func=lambda nlls: torch.exp(-performance_weighting*nlls))\n",
    "            test_rmse_perf_weighting = _gp_pop.gp_mixture_rmse(test_y, weight_func=lambda nlls: torch.exp(-performance_weighting*nlls))\n",
    "            # compute NLL RMSE using uniform weighting\n",
    "            test_nll_uniform_weighting = _gp_pop.gp_mixture_nll(test_y, weight_func=lambda nlls: torch.ones_like(nlls))\n",
    "            test_rmse_uniform_weighting = _gp_pop.gp_mixture_rmse(test_y, weight_func=lambda nlls: torch.ones_like(nlls))\n",
    "            mixture_nll_perf_weighting[n_gps] = test_nll_perf_weighting\n",
    "            mixture_rmse_perf_weighting[n_gps] = test_rmse_perf_weighting\n",
    "            mixture_nll_uniform_weighting[n_gps] = test_nll_uniform_weighting\n",
    "            mixture_rmse_uniform_weighting[n_gps] = test_rmse_uniform_weighting\n",
    "            \n",
    "        del _gp_pop, test_y, train_x, train_y, test_x\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        mixture_nll_perf_weightings.append(mixture_nll_perf_weighting)\n",
    "        mixture_rmse_perf_weightings.append(mixture_rmse_perf_weighting)\n",
    "        mixture_nll_uniform_weightings.append(mixture_nll_uniform_weighting)\n",
    "        mixture_rmse_uniform_weightings.append(mixture_rmse_uniform_weighting)\n",
    "        \n",
    "    \n",
    "    test_rmses_all[name] = test_rmses\n",
    "    test_nlls_all[name] = test_nlls\n",
    "    train_times_all[name] = train_times\n",
    "    predict_times_all[name] = predict_times\n",
    "    init_times_all[name] = init_times\n",
    "    mixture_rmse_all_perf_weighting[name] = mixture_rmse_perf_weightings\n",
    "    mixture_nll_all_perf_weighting[name] = mixture_nll_perf_weightings\n",
    "    mixture_rmse_all_uniform_weighting[name] = mixture_rmse_uniform_weightings\n",
    "    mixture_nll_all_uniform_weighting[name] = mixture_nll_uniform_weightings\n",
    "    mixture_nll_all_uniform_weighting[name] = mixture_nll_uniform_weightings\n",
    "    all_last_bit_weights[name] = mixture_last_bit_weights\n",
    "    all_init_bit_orders[name] = mixture_init_bit_orders\n",
    "    all_final_bit_orders[name] = mixture_final_bit_orders\n",
    "    with open(f\"uci_results_mixture_ensemble_{name}_torch_bfgs_160_raw_samps.data\", \"wb\") as f:\n",
    "        torch.save({\n",
    "            \"test_rmses_all\": test_rmses_all, \n",
    "            \"test_nlls_all\": test_nlls_all, \n",
    "            \"train_times_all\": train_times_all, \n",
    "            \"predict_times_all\": predict_times_all,\n",
    "            \"init_times_all\": init_times_all,\n",
    "            \"mixture_rmses_all_perf_weighting\": mixture_rmse_all_perf_weighting,\n",
    "            \"mixture_nlls_all_perf_weighting\": mixture_nll_all_perf_weighting,\n",
    "            \"mixture_rmses_all_uniform_weighting\": mixture_rmse_all_uniform_weighting,\n",
    "            \"mixture_nlls_all_uniform_weighting\": mixture_nll_all_uniform_weighting,\n",
    "            \"all_last_bit_weights\": all_last_bit_weights,\n",
    "            \"all_init_bit_orders\": all_init_bit_orders,\n",
    "            \"all_final_bit_orders\": all_final_bit_orders,\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f7f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{5: tensor(0.0291, device='cuda:5', dtype=torch.float64),\n",
       "  10: tensor(0.0283, device='cuda:5', dtype=torch.float64),\n",
       "  15: tensor(0.0283, device='cuda:5', dtype=torch.float64),\n",
       "  20: tensor(0.0283, device='cuda:5', dtype=torch.float64)},\n",
       " {5: tensor(0.0290, device='cuda:5', dtype=torch.float64),\n",
       "  10: tensor(0.0290, device='cuda:5', dtype=torch.float64),\n",
       "  15: tensor(0.0283, device='cuda:5', dtype=torch.float64),\n",
       "  20: tensor(0.0284, device='cuda:5', dtype=torch.float64)},\n",
       " {5: tensor(0.0295, device='cuda:5', dtype=torch.float64),\n",
       "  10: tensor(0.0296, device='cuda:5', dtype=torch.float64),\n",
       "  15: tensor(0.0292, device='cuda:5', dtype=torch.float64),\n",
       "  20: tensor(0.0292, device='cuda:5', dtype=torch.float64)}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_rmse_perf_weightings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05f11d",
   "metadata": {},
   "source": [
    "         ## test SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e038e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $0.029 \\pm 0.001$\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "for k, v in mixture_rmse_all_perf_weighting.items():\n",
    "    v = torch.cat([vi[20].view(1) for vi in v])\n",
    "    m = round(v.mean().item(), 3)\n",
    "    two_se = round(2*v.std().item()/sqrt(3), 3)\n",
    "    print(f\"{k} & ${m:.3f} \\pm {two_se:.3f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a171935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $0.029 \\pm 0.001$\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "for k, v in test_rmses_all.items():\n",
    "    v = torch.cat([vi.view(1) for vi in v])\n",
    "    m = round(v.mean().item(), 3)\n",
    "    two_se = round(2*v.std().item()/sqrt(3), 3)\n",
    "    print(f\"{k} & ${m:.3f} \\pm {two_se:.3f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47335af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $-2.569 \\pm 0.006$\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "for k, v in mixture_nll_all_perf_weighting.items():\n",
    "    v = torch.cat([vi[20].view(1) for vi in v])\n",
    "    v = v[~torch.isnan(v)]\n",
    "    m = round(v.mean().item(), 3)\n",
    "    two_se = round(2*v.std().item()/sqrt(3), 3)\n",
    "    print(f\"{k} & ${m:.3f} \\pm {two_se:.3f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be5ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $-2.492 \\pm 0.012$\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "for k, v in test_nlls_all.items():\n",
    "    v = torch.cat([vi.view(1) for vi in v])\n",
    "    m = round(v.mean().item(), 3)\n",
    "    two_se = round(2*v.std().item()/sqrt(3), 3)\n",
    "    print(f\"{k} & ${m:.3f} \\pm {two_se:.3f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d193ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $6643.4 \\pm 235.9$\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "name_to_train_time = {}\n",
    "for name in train_times_all.keys():\n",
    "    start = 0\n",
    "    end = NUM_RESTARTS\n",
    "    train_times = train_times_all[name]\n",
    "    time_per_seed = []\n",
    "    while start < len(train_times):\n",
    "        time_per_seed.append(sum(train_times[start:end]))\n",
    "        start = end\n",
    "        end += NUM_RESTARTS\n",
    "    time_per_seed = np.array(time_per_seed)\n",
    "    v = time_per_seed\n",
    "    m = round(v.mean(), 1)\n",
    "    two_se = round(2*v.std()/sqrt(3), 1)\n",
    "    print(f\"{name} & ${m:.1f} \\pm {two_se:.1f}$\")\n",
    "    name_to_train_time[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10fa70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric & $7104.3 \\pm 235.9$\n"
     ]
    }
   ],
   "source": [
    "# all times\n",
    "import numpy as np\n",
    "for name in init_times_all.keys():\n",
    "    v = np.array(init_times_all[name]) + name_to_train_time[name]\n",
    "    m = round(v.mean(), 1)\n",
    "    two_se = round(2*v.std()/sqrt(3), 1)\n",
    "    print(f\"{name} & ${m:.1f} \\pm {two_se:.1f}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6aa6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
